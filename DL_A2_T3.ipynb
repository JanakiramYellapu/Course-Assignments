{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_A2_T3",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CGDHoAGlRNj",
        "colab_type": "code",
        "outputId": "c4fa40c9-e65c-4fc9-c88f-dcd7eb9b41c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcbzLvWSyDnI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0v095NlOyEkc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reading data \n",
        "no_of_classes = 5                        #Change this ******\n",
        "path = \"/content/drive/My Drive/DL A2/\"\n",
        "filenames = {\"Ankle boot.csv\" : 0, \"Bag.csv\" : 1, \"Coat.csv\" : 2, \"Shirt.csv\" : 3, \"Trouser.csv\" : 4}\n",
        "data = []\n",
        "labels = []\n",
        "\n",
        "for (name, index) in filenames.items():\n",
        "  pathname = path + name\n",
        "  df = pd.read_csv( pathname , delimiter =',', header = None)\n",
        "  data.append(df)\n",
        "  for i in range(df.shape[0]):\n",
        "    labels.append(index)\n",
        "df = pd.concat(data, axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gItXyvCxz70W",
        "colab_type": "code",
        "outputId": "d085b8a8-f14b-4506-9024-9748f9814819",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30000, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCk84AQXaWmE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWR4NCaZY50W",
        "colab_type": "code",
        "outputId": "1807cbad-0f13-4bb3-a08b-6c1165bd6b41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03NAgvTU03Fz",
        "colab_type": "code",
        "outputId": "f3a2a793-c64f-4074-f538-8a19be637a89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "plt.imshow( np.array(df.tail(1)).reshape(28,28), cmap ='gray')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f449f565ba8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyVTBvYx2X9f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model = tf.keras.models.Sequential([\n",
        "#     tf.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "#     tf.keras.layers.MaxPooling2D(2, 2),\n",
        "#     tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "#     tf.keras.layers.MaxPooling2D(2, 2),\n",
        "#     tf.keras.layers.Flatten(),\n",
        "#     tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "#     tf.keras.layers.Dense(26, activation=tf.nn.softmax)])\n",
        "\n",
        "# model.compile(optimizer = tf.train.AdamOptimizer(),\n",
        "#               loss = 'sparse_categorical_crossentropy',\n",
        "#               metrics=['accuracy'])\n",
        "\n",
        "# history = model.fit_generator(train_datagen.flow(training_images, training_labels, batch_size=32),\n",
        "#                               steps_per_epoch=len(training_images) / 32,\n",
        "#                               epochs=15,\n",
        "#                               validation_data=validation_datagen.flow(testing_images, testing_labels, batch_size=32),\n",
        "#                               validation_steps=len(testing_images) / 32)\n",
        "\n",
        "# model.evaluate(testing_images, testing_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ks9lYgj_16r9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Auto encoder\n",
        "def autoencoder(X, hunits, epochs = 0):\n",
        "  input_shape = X.shape[1]\n",
        "  model = tf.keras.models.Sequential([\n",
        "                  tf.keras.layers.Dense(hunits, activation = tf.nn.relu, input_dim = input_shape),\n",
        "                  tf.keras.layers.Dense(input_shape, activation = tf.nn.relu)\n",
        "  ])\n",
        "  model.compile(loss = tf.losses.mean_squared_error, metrics = 'mse')\n",
        "  model.summary()\n",
        "  model.fit(X, X, epochs = epochs)\n",
        "  return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxOCgL2FMQxX",
        "colab_type": "code",
        "outputId": "481c87ea-f3d0-4334-c174-c4aaf5ed13f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# Splitting data into test and train \n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_data, test_data, train_labels , test_labels = train_test_split(df, labels, test_size=0.2, random_state = 1)\n",
        "\n",
        "# Training data\n",
        "train_data  = tf.convert_to_tensor(train_data, dtype ='float32')\n",
        "train_labels = tf.convert_to_tensor(train_labels)\n",
        "print(train_data.shape)\n",
        "print(train_labels.shape)\n",
        "\n",
        "# Testing data\n",
        "test_data  = tf.convert_to_tensor(test_data, dtype ='float32')\n",
        "test_labels = tf.convert_to_tensor(test_labels)\n",
        "print(test_data.shape)\n",
        "print(test_labels.shape)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(24000, 784)\n",
            "(24000,)\n",
            "(6000, 784)\n",
            "(6000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhKMuv7AFieh",
        "colab_type": "code",
        "outputId": "6c38a13d-3f1e-4f0e-bebb-d0637c7acb3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "# Layer 1 784 t0 500\n",
        "\n",
        "layer1_model = autoencoder(train_data, 500, epochs = 5)\n",
        "(W1, b1, W2, b2) = layer1_model.trainable_variables\n",
        "params_layer1 = {\"W1\" : W1, \"W2\" : W2, \"b1\": b1, \"b2\":b2}\n",
        "print(\"W1.shape : \",params_layer1[\"W1\"].shape )\n",
        "print(\"b1.shape : \", params_layer1[\"b1\"].shape)\n",
        "print(\"W2.shape : \", params_layer1[\"W2\"].shape)\n",
        "print(\"b2.shape : \", params_layer1[\"b2\"].shape)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 500)               392500    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 784)               392784    \n",
            "=================================================================\n",
            "Total params: 785,284\n",
            "Trainable params: 785,284\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 2090.9819 - mse: 2090.9819\n",
            "Epoch 2/5\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 1272.5765 - mse: 1272.5765\n",
            "Epoch 3/5\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 1052.1108 - mse: 1052.1108\n",
            "Epoch 4/5\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 976.1626 - mse: 976.1626\n",
            "Epoch 5/5\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 932.2503 - mse: 932.2503\n",
            "W1.shape :  (784, 500)\n",
            "b1.shape :  (500,)\n",
            "W2.shape :  (500, 784)\n",
            "b2.shape :  (784,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRSNHo84Oxey",
        "colab_type": "code",
        "outputId": "de76d85a-5381-4d36-eef8-d43a0bc09940",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "layer2_input = tf.nn.relu(tf.matmul( train_data, params_layer1[\"W1\"]) + params_layer1[\"b1\"])\n",
        "print(\"layer2_input shape : \", layer2_input.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "layer2_input shape :  (24000, 500)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vk-NX44OF1-6",
        "colab_type": "code",
        "outputId": "69415c3d-15f3-429f-8781-c3aae64ef879",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "# Training layer 2\n",
        "\n",
        "layer2_model = autoencoder(layer2_input, 300, 5)\n",
        "(W1, b1, W2, b2) = layer2_model.trainable_variables\n",
        "params_layer2 = {\"W1\" : W1, \"W2\" : W2, \"b1\": b1, \"b2\":b2}\n",
        "print(\"W1.shape : \",params_layer2[\"W1\"].shape )\n",
        "print(\"b1.shape : \", params_layer2[\"b1\"].shape)\n",
        "print(\"W2.shape : \", params_layer2[\"W2\"].shape)\n",
        "print(\"b2.shape : \", params_layer2[\"b2\"].shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_2 (Dense)              (None, 300)               150300    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 500)               150500    \n",
            "=================================================================\n",
            "Total params: 300,800\n",
            "Trainable params: 300,800\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 1535.5483 - mse: 1535.5483\n",
            "Epoch 2/5\n",
            "750/750 [==============================] - 3s 5ms/step - loss: 1049.4769 - mse: 1049.4769\n",
            "Epoch 3/5\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 994.9580 - mse: 994.9580\n",
            "Epoch 4/5\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 960.9908 - mse: 960.9908\n",
            "Epoch 5/5\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 911.6901 - mse: 911.6901\n",
            "W1.shape :  (500, 300)\n",
            "b1.shape :  (300,)\n",
            "W2.shape :  (300, 500)\n",
            "b2.shape :  (500,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSNdG4BrQMp5",
        "colab_type": "code",
        "outputId": "7f1e48a9-a93a-4248-beb5-ee33ca1c41db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "layer3_input = tf.nn.relu(tf.matmul( layer2_input, params_layer2[\"W1\"]) + params_layer2[\"b1\"])\n",
        "print(\"layer3_input shape : \", layer3_input.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "layer3_input shape :  (24000, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ux_mtGVARLf7",
        "colab_type": "code",
        "outputId": "bdb5bca2-2d5d-4349-bce4-6874e81598af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "# Training layer 3\n",
        "\n",
        "layer3_model = autoencoder(layer3_input, 100, 5)\n",
        "(W1, b1, W2, b2) = layer3_model.trainable_variables\n",
        "params_layer3 = {\"W1\" : W1, \"W2\" : W2, \"b1\": b1, \"b2\":b2}\n",
        "print(\"W1.shape : \",params_layer3[\"W1\"].shape )\n",
        "print(\"b1.shape : \", params_layer3[\"b1\"].shape)\n",
        "print(\"W2.shape : \", params_layer3[\"W2\"].shape)\n",
        "print(\"b2.shape : \", params_layer3[\"b2\"].shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_4 (Dense)              (None, 100)               30100     \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 300)               30300     \n",
            "=================================================================\n",
            "Total params: 60,400\n",
            "Trainable params: 60,400\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "750/750 [==============================] - 1s 1ms/step - loss: 2444.6301 - mse: 2444.6301\n",
            "Epoch 2/5\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 1232.4927 - mse: 1232.4927\n",
            "Epoch 3/5\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 1034.1514 - mse: 1034.1514\n",
            "Epoch 4/5\n",
            "750/750 [==============================] - 1s 1ms/step - loss: 957.9502 - mse: 957.9502\n",
            "Epoch 5/5\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 919.3559 - mse: 919.3559\n",
            "W1.shape :  (300, 100)\n",
            "b1.shape :  (100,)\n",
            "W2.shape :  (100, 300)\n",
            "b2.shape :  (300,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSbvuYs3RY_O",
        "colab_type": "code",
        "outputId": "c6d441ed-f6d6-4e9f-8b5e-fce41e8da50c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "softmax_input = tf.nn.relu(tf.matmul( layer3_input, params_layer3[\"W1\"]) + params_layer3[\"b1\"])\n",
        "print(\"softmax_input shape : \", softmax_input.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "softmax_input shape :  (24000, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bk-Fn4KxRph_",
        "colab_type": "code",
        "outputId": "f0a5309d-68b8-463c-dfa0-cce61e8d4abe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "# Training softmax layer\n",
        "softmax_model = tf.keras.models.Sequential([\n",
        "                        tf.keras.layers.Dense(no_of_classes, activation = tf.nn.softmax, input_dim = softmax_input.shape[1])\n",
        "])\n",
        "softmax_model.compile(loss = tf.losses.sparse_categorical_crossentropy, metrics =['accuracy'])\n",
        "softmax_model.fit(softmax_input, train_labels, epochs = 5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "750/750 [==============================] - 1s 989us/step - loss: 19.5021 - accuracy: 0.7818\n",
            "Epoch 2/10\n",
            "750/750 [==============================] - 1s 1ms/step - loss: 5.1834 - accuracy: 0.8933\n",
            "Epoch 3/10\n",
            "750/750 [==============================] - 1s 1ms/step - loss: 3.7502 - accuracy: 0.9025\n",
            "Epoch 4/10\n",
            "750/750 [==============================] - 1s 980us/step - loss: 3.0192 - accuracy: 0.9030\n",
            "Epoch 5/10\n",
            "750/750 [==============================] - 1s 995us/step - loss: 2.5563 - accuracy: 0.9049\n",
            "Epoch 6/10\n",
            "750/750 [==============================] - 1s 975us/step - loss: 2.2579 - accuracy: 0.9050\n",
            "Epoch 7/10\n",
            "750/750 [==============================] - 1s 1ms/step - loss: 2.1313 - accuracy: 0.9012\n",
            "Epoch 8/10\n",
            "750/750 [==============================] - 1s 939us/step - loss: 1.9491 - accuracy: 0.9015\n",
            "Epoch 9/10\n",
            "750/750 [==============================] - 1s 978us/step - loss: 1.8951 - accuracy: 0.9024\n",
            "Epoch 10/10\n",
            "750/750 [==============================] - 1s 959us/step - loss: 1.8033 - accuracy: 0.9008\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f448e003d68>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8UwYPe9bmUd",
        "colab_type": "code",
        "outputId": "4b6a4c4b-434a-4302-8ea5-5b2c83fac361",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Parameters of softmax layer\n",
        "\n",
        "(W1, b1) = softmax_model.trainable_variables\n",
        "params_softmax = {\"W1\" : W1, \"b1\":b1} \n",
        "print(\"W1.shape\", params_softmax[\"W1\"].shape)\n",
        "print(\"b1.shape\", params_softmax[\"b1\"].shape)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W1.shape (100, 5)\n",
            "b1.shape (5,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJDYS0KTgHQW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build a model using pre training W and b parameters \n",
        "# 784 -> 500 -> 300 -> 100 ->softmax()\n",
        "\n",
        "# finalModel = tf.keras.models.Sequential([\n",
        "#                   tf.keras.layers.Dense(500, activation= tf.nn.relu, input_dim = 784, \n",
        "#                            bias_initializer = tf.convert_to_tensor(params_layer1[\"b1\"], dtype ='float32')),\n",
        "#                   tf.keras.layers.Dense(300, activation= tf.nn.relu,\n",
        "#                           kernel_initializer = params_layer2[\"W1\"], bias_initializer = params_layer2[\"b1\"]),\n",
        "#                   tf.keras.layers.Dense(100, activation= tf.nn.relu,\n",
        "#                           kernel_initializer = params_layer3[\"W1\"], bias_initializer = params_layer3[\"b1\"]),\n",
        "#                   tf.keras.layers.Dense(no_of_classes,activation= tf.nn.relu,\n",
        "#                           kernel_initializer = params_softmax[\"W1\"], bias_initializer = params_softmax[\"b1\"]),\n",
        "# ])\n",
        "# finalModel.compile( loss = tf.losses.sparse_categorical_crossentropy, metrics =['accuraccy'])\n",
        "# finalModel.fit(train_data, train_labels, epochs =10)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nhlCbVOiB8a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# finalModel.evaluate(test_data, test_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THGQpmNPkWlA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tf.keras.layers.Dense?"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pm5_7fZltkXh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layer2_input = tf.nn.relu(tf.matmul( test_data, params_layer1[\"W1\"]) + params_layer1[\"b1\"])\n",
        "layer3_input = tf.nn.relu(tf.matmul( layer2_input, params_layer2[\"W1\"]) + params_layer2[\"b1\"])\n",
        "softmax_input = tf.nn.relu(tf.matmul( layer3_input, params_layer3[\"W1\"]) + params_layer3[\"b1\"])\n",
        "output = tf.nn.softmax(tf.matmul( softmax_input, params_softmax[\"W1\"]) + params_softmax[\"b1\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIM55rqpv1Ec",
        "colab_type": "code",
        "outputId": "df410605-58e1-4318-c295-2cdf6d66af80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "output.shape\n",
        "# test_labels.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([6000, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1ZFCXXLA6O_",
        "colab_type": "code",
        "outputId": "31b880dd-8991-4859-b6ec-c81e7769f9ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.argmax(output[1])\n",
        "output[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5,), dtype=float32, numpy=array([0., 1., 0., 0., 0.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SK5gMrfyBKCF",
        "colab_type": "code",
        "outputId": "68f46626-79db-4d2f-bd21-7af153c18d65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Testing accuracy\n",
        "count = 0\n",
        "for i in range(output.shape[0]):\n",
        "  label = np.argmax(output[i])\n",
        "  if(label == test_labels[i]):\n",
        "    count += 1;\n",
        "\n",
        "count/6000"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8673333333333333"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    }
  ]
}